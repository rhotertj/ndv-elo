extends: .github/workflows/setup.yml

jobs:
  crawl:
    needs: setup
    runs-on: ubuntu-latest

    services:
      selenium:
        image: selenium/standalone-chrome
        ports:
          - 4444/tcp

    steps:
    - uses: actions/checkout@v2

    - name: Run Selenium crawler script
      run: |
        pip install -r requirements.txt
        mkdir data
        # date -d "2 days ago" +"%Y-%m-%d"
        python scripts/crawl_concurrently.py --path ./data --season $CURRENT_SEASON --server http://selenium:4444
        python scripts/insert_data.py -db $DB_FILENAME --data ./data/*.json

    - name: Upload database as artifact
      uses: actions/upload-artifact@v2
      with:
        name: $DB_FILENAME
        path: artifacts
